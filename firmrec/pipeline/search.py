#!python
# -*- coding: utf-8 -*-
"""
This file is used to search inputs and extract information for exploitation simulation
We provide several searchers, where VarCLRNamedConstantSearcher is not used:
 - LLMNamedConstantSearcher: search named constants with LLM
 - HeuristicNamedConstantSearcher: search named constants with heuristic 
    (Used to complement LLMNamedConstantSearcher by subwords)
 - UnnamedConstantSearcher: search unnamed constants with exactly matching
 - VarCLRNamedConstantSearcher: search named constants with VarCLR (Not recommended)
"""

import sys
import os
import argparse
import re
import json
import struct
import base64
from itertools import groupby
from functools import reduce, cached_property

import yaml
import psycopg2

from firmlib import is_func_name
from ..models.target_info import TargetInfo
from .search_prepare import (
    load_name_sim_dictionary,
    load_named_input_entries,
    load_unnamed_input_entries,
    FETCH_NAMED_ENTRIES_CMD,
)

os.environ["TRANSFORMERS_OFFLINE"] = "1"

UNPACK_DIR = "unpacked"


class KeywordHiearchyTree:
    """A keyword hiearchy tree used for keyword processing and searching"""

    # pylint: disable=line-too-long
    SEP_PATTERN = r"(\r|\^|\x20|\&|\,|\?|\'|\@|\#|\;|\\|\-|\*|\[|\x0b|\>|\t|\~|\]|\`|\=|\_|\"|\!|\%|\)|\(|\}|\$|\||\:|\/|\{|\.|\+|\<|\n|\x0c|[0-9]+)"
    SIM_DICTIONARY = {
        "password": "passwd",
        "passwd": "password",
        "user": "username",
        "username": "user",
        "desc": "description",
        "description": "desc",
    }

    def __init__(self, keyword: str, enable_dictionary=True) -> None:
        """create a keyword hiearchy tree"""
        self.keyword = keyword
        self.tokens = self.sep(keyword)
        self.enable_dictionary = enable_dictionary

    @property
    def needles(self):
        """
        Get needles of keyword
        """
        needle = ""
        results = []
        for token in reversed(self.tokens):
            needle = token + needle
            if re.match(self.SEP_PATTERN, token):
                continue
            if len(token) < 2:
                continue
            results.append(needle)
        entity = results[0]
        results = results[::-1]
        if self.enable_dictionary and entity in self.SIM_DICTIONARY:
            results.append(self.SIM_DICTIONARY[entity])
        return results

    @classmethod
    def sep(cls, keyword: str):
        """
        Seperate keywords to tokens
        """
        tokens = cls.sep_by_token(keyword)
        tokens = list(
            reduce(lambda x, y: x + y, list(map(cls.sep_by_case, tokens)), [])
        )
        return tokens

    @classmethod
    def sep_by_token(cls, keyword: str):
        """
        Sperate keyword by token
        For example 'filter_proto_en' -> ['filter', 'proto', 'en']
        """
        # set(string.printable) - set(string.ascii_letters)
        splits = [x for x in re.split(cls.SEP_PATTERN, keyword) if x]
        return splits

    @classmethod
    def sep_by_case(cls, keyword: str):
        """
        Seperate keyword by case
        For example 'arpBroadcast' -> ['arp', 'Broadcast']
        We assume keyword
        """
        result = []
        if not keyword:
            return result
        prev_idx = 0
        prev_case = keyword[0].isupper()
        for curr_idx, character in enumerate(keyword):
            curr_case = character.isupper()
            if curr_case != prev_case:
                if not prev_case:
                    # lower -> upper
                    result.append(keyword[prev_idx:curr_idx])
                    prev_idx = curr_idx
                else:
                    # upper -> lower
                    pass
            prev_case = curr_case
        result.append(keyword[prev_idx:])
        return result


class InputSearchManager:
    """Input search manager that search semantically similar input entries
    :param conn: database connection
    :param func_models: function models that is used to filter FP named input entries
    :param named_input_entries_path: path to named input entries
    :param unnamed_inpt_entries_path: path to unnamed input entries
    :param name_sim_dictionary_path: path to name similarity dictionary, generated by LLM-based search
    """

    def __init__(
        self,
        conn,
        func_models,
        named_input_entries_path,
        unnamed_inpt_entries_path,
        name_sim_dictionary_path=None,
    ) -> None:
        # connect to database
        self.conn = conn
        self.conn.autocommit = False
        self.func_models = func_models
        self.named_input_entries = load_named_input_entries(
            conn, named_input_entries_path, func_models
        )
        self.unnamed_input_entries = load_unnamed_input_entries(
            conn, unnamed_inpt_entries_path
        )
        if name_sim_dictionary_path:
            self.name_sim_dictionary = load_name_sim_dictionary(
                name_sim_dictionary_path
            )
        else:
            self.name_sim_dictionary = {}

        print(f"There are {len(self.named_input_entries)} named input entries")
        print(f"There are {len(self.unnamed_input_entries)} unnamed input entries")
        print(f"There are {len(self.name_sim_dictionary)} similar pairs")

        self.searchers = {
            # "kv": HeuristicNamedConstantSearcher(
            #     conn=self.conn,
            #     entries=self.named_input_entries,
            #     func_models=self.func_models,
            # ),
            "kv": LLMNamedConstantSearcher(
                conn=self.conn,
                entries=self.named_input_entries,
                func_models=self.func_models,
                name_sim_dictionary=self.name_sim_dictionary,
            ),
            "raw": UnnamedConstantSearcher(
                conn=self.conn,
                entries=self.named_input_entries,
                func_models=self.func_models,
            ),
        }

    def search(self, knowledge, *args, **kwargs) -> list:
        """
        This method search keyword in database
        """
        protocol = knowledge["target"]["protocol"]
        if protocol not in self.searchers:
            raise NotImplementedError(f"Unknown protocol {protocol}")

        searcher: ConstantSearcher = self.searchers[protocol]
        search_results = searcher.search(
            knowledge, self.named_input_entries, *args, **kwargs
        )
        return searcher.build_simexp_inputs(search_results, knowledge)


class ConstantSearcher:
    """Base class for constant searchers"""

    def __init__(self, conn, entries, func_models, *args, **kwargs):
        self.conn = conn
        self.entries = entries
        self.func_models = func_models

    def search(self, knowledge, *args, **kwargs) -> list:
        """
        This method search keyword to find entries
        """
        raise NotImplementedError("search not implemented")

    def build_simexp_inputs(self, filtered_search_results, knowledge):
        """Build inputs for simulation exploitation"""
        # TODO: handle raw protocol
        func_models = self.func_models

        results = []
        for search_result in filtered_search_results:
            # we may try several entry addresses
            entry_funcs = self.get_possible_entry_funcs(
                search_result["bin_id"], int(search_result["caller_func_addr"], 16)
            )

            source_func_id = search_result["source_func_id"]
            source_func_name = search_result["source_func_name"]

            key = f"{source_func_id} {source_func_name}"
            model = func_models.get(key, None)

            for out_arg in model["out_arg"]:
                # Build source information
                source_info = self._build_source_info(search_result, model, out_arg)

                for entry_func in entry_funcs:
                    result = self._build_one_simexp_inputs(
                        knowledge, search_result, entry_func, source_info
                    )
                    results.append(result)

        return results

    def _build_source_info(self, search_result, model, out_arg):
        """Build source function information"""

        source_func_name = search_result["source_func_name"]
        source_func_addr = search_result["source_func_addr"]

        source_info_raw = dict(model)
        source_info_raw["addr"] = source_func_addr
        source_info_raw["out_arg"] = out_arg
        if is_func_name(source_func_name):
            source_info_raw["name"] = source_func_name
        else:
            source_info_raw["name"] = ""
        source_info = [source_info_raw]

        return source_info

    def _build_one_simexp_inputs(
        self, knowledge, search_result, entry_func, source_info
    ):
        """Build extra_info for simulation exploitation"""
        vuln_name = knowledge["vuln_name"]
        vuln_vendor = knowledge["vuln_vendor"]
        keyword = knowledge["target"]["keyword"]

        firmware_id = search_result["firmware_id"]
        vendor = search_result["vendor"]
        path = search_result["path"]
        bin_path = os.path.join(UNPACK_DIR, vendor, firmware_id, path)
        base_addr = search_result["base_addr"]

        found_keyword = search_result["keyword"]

        entry_addr = entry_func["address"]
        raw_extra_info = entry_func["extra_info"]

        # Build extra information
        extra_info = {"conc_regs": {}}
        if "gp" in raw_extra_info:
            extra_info["conc_regs"]["gp"] = raw_extra_info["gp"]
        if "t9" in raw_extra_info:
            extra_info["conc_regs"]["t9"] = raw_extra_info["t9"]

        extra_info["knowledge"] = {
            "vuln_name": vuln_name,
            "input_id": search_result["input_id"],
            "keyword": keyword,
            "found_keyword": found_keyword,
            "source_func_name": search_result["source_func_name"],
            "caller_func_name": search_result["caller_func_name"],
        }

        # Build PoC information
        poc_info = extra_info["poc_info"] = dict(
            knowledge["poc_info"]
        )
        if found_keyword != keyword:
            poc_info["keywords"] = list(set([found_keyword] + poc_info["keywords"]))
            poc_info["key_keywords"] = [found_keyword]
            inputs = poc_info["input"] = dict(poc_info["input"])
            kv = inputs["kv"] = dict(inputs["kv"])
            kv[found_keyword] = poc_info["input"]["kv"][keyword]

        # white call
        white_call_names = knowledge.get("white_calls", [])
        extra_info["white_calls"] = self._get_func_addrs_by_names(
            firmware_id, path, white_call_names
        )

        # We only use library paths when the vendor is the same as the vulnerability
        if vendor == vuln_vendor:
            lib_paths = []
            for lib_rel_path in knowledge.get("lib_paths", []):
                unpacked_dir = os.path.join(UNPACK_DIR, vendor, firmware_id)
                lib_path = os.path.join(unpacked_dir, lib_rel_path)
                if os.path.isfile(lib_path):
                    lib_paths.append(lib_path)
        else:
            lib_paths = []

        arch = None  # we process ELFs only, so don't specify arch

        result = dict(
            vuln_name=vuln_name,
            firmware_id=firmware_id,
            vendor=vendor,
            path=path,
            bin_path=bin_path,
            base_addr=base_addr,
            entry_addr=entry_addr,
            arch=arch,
            lib_paths=lib_paths,
            source_info=source_info,
            extra_info=extra_info,
        )
        return result

    def _get_uniq_results(self, results):
        visited = set()
        uniq_results = []
        for result in results:
            uniq_identifier = tuple(result.items())
            if uniq_identifier in visited:
                continue
            visited.add(uniq_identifier)
            uniq_results.append(result)
        return uniq_results

    def _get_func_addrs_by_names(self, firmware_id, bin_path, names):
        """Get function addresses by names"""
        if not names:
            return []
        cmd = """
        SELECT address
        FROM func
        WHERE bin_id in (
            SELECT id
            FROM bin
            WHERE firmware_id = %s AND path = %s
        ) AND name IN %s
        """
        cur = self.conn.cursor()
        cur.execute(cmd, (firmware_id, bin_path, tuple(names)))
        results = fetch_data(cur, many=True)
        cur.close()
        return [result["address"] for result in results]

    def _get_relevant_funcs_by_vuln(self, image_filename, bin_path, keyword):
        """Get functions relevant to vulnerability"""
        cur = self.conn.cursor()

        cmd = """
        SELECT caller.name AS caller_name, callee.name AS callee_name
        FROM func_call 
            JOIN func AS callee ON func_call.callee = callee.id
            JOIN func AS caller ON func_call.caller = caller.id
        WHERE caller.bin_id IN (
            SELECT id
            FROM bin
            WHERE firmware_id = %s AND path = %s
        )
        """
        cur.execute(cmd, (image_filename.split("/", 1)[1], bin_path))
        results = fetch_data(cur, many=True)
        cur.close()

        return results

    def _get_dataflow_features_by_vuln(self, image_filename, bin_path, keyword):
        """Get dataflow features relevant to vulnerability"""
        cur = self.conn.cursor()

        cmd = """
        SELECT *
        FROM input_dataflow_call
        WHERE input_id IN (
            SELECT id
            FROM input
            WHERE bin_id IN (
                SELECT id
                FROM bin
                WHERE firmware_id = %s AND path = %s
            ) AND keyword = %s
        )
        """
        cur.execute(cmd, (image_filename.split("/", 1)[1], bin_path, keyword))
        results = fetch_data(cur, many=True)
        cur.close()

        return results

    def get_possible_entry_funcs(self, bin_id, caller_addr: int):
        """
        Find possible entry functions of caller
        """
        cursor = self.conn.cursor()
        # TODO: we may also need to consider callers of callers
        # funcs = self.find_caller_funcs(bin_id, callee_addr)
        cursor = self.conn.cursor()
        cmd = """
        SELECT func.address AS address, 
            (CASE
                WHEN func.extra_info LIKE %s 
                THEN func.extra_info::jsonb
                ELSE '{}'::jsonb 
            END) AS extra_info
        FROM func
        WHERE func.address = %s AND func.bin_id = %s
        ;
        """
        cursor.execute(cmd, ("{%}", caller_addr, bin_id))
        funcs = fetch_data(cursor, many=True)
        cursor.close()
        return funcs

    def _find_caller_funcs(self, bin_id: int, callee_addr: int):
        """
        Find caller functions of callee
        """
        cursor = self.conn.cursor()
        cmd = """
        SELECT caller.address AS address, 
            (CASE
                WHEN caller.extra_info LIKE %s 
                THEN caller.extra_info::jsonb
                ELSE '{}'::jsonb 
            END) AS extra_info
        FROM func_call 
            JOIN func AS callee ON func_call.callee = callee.id
            JOIN func AS caller ON func_call.caller = caller.id
        WHERE callee.address = %s AND callee.bin_id = %s
        ;
        """
        cursor.execute(cmd, ("{%}", callee_addr, bin_id))
        results = fetch_data(cursor, many=True)
        cursor.close()
        return results


class UnnamedConstantSearcher(ConstantSearcher):
    """
    Search unnamed constants with exactly matching
    """

    def search(self, knowledge, *args, **kwargs) -> list:
        """
        This method search keyword in database
        """
        print("Searching with UnnamedConstantSearcher")
        protocol = knowledge["target"]["protocol"]
        assert protocol == "raw"

        constant = knowledge["target"]["constant"]
        return self.search_by_constant(constant)

    def search_by_constant(self, constant):
        """
        Search the input database to find entries by constants
        """
        # get cursor

        print(f"Search constant {constant}")

        search_results = []
        for entry in self.entries:
            if constant in entry["constants"]:
                search_results.append(entry)

        return search_results


class HeuristicNamedConstantSearcher(ConstantSearcher):
    """
    Search named constants with heuristic
    """

    def search(self, knowledge, *args, **kwargs) -> list:
        """
        This method search keyword in database
        """
        print("Searching with HeuristicNamedConstantSearcher")
        exact = kwargs.get("exact", False)
        protocol = knowledge["target"]["protocol"]
        assert protocol == "kv"

        keyword = knowledge["target"]["keyword"]

        search_results = self.search_by_keyword(
            keyword, case_sensitive=exact, exact=exact
        )
        print(
            f"Found {len(search_results)} inputs by keyword {keyword} (case insensitive)"
        )
        if not exact and len(search_results) > 600:
            search_results = self.search_by_keyword(keyword, case_sensitive=True)
            print(
                f"Found {len(search_results)} inputs by keyword {keyword} (case sensitive)"
            )

        return search_results

    def search_by_keyword(self, keyword, case_sensitive=False, exact=False):
        """
        Search the input database to find semantically similar input by keyword
        """
        kht = KeywordHiearchyTree(keyword)

        # get cursor
        cur = self.conn.cursor()

        # execute sql
        results = []

        search_patterns = []

        pattern_methods = []

        # TODO: filter by entries
        def get_number_pattern_methods(needle):
            pattern = f"{re.sub(r'([0-9]+)', '%d', re.escape(needle))}"
            method = """is NULL AND EXISTS (
                SELECT *
                FROM input_dataflow_call AS dfc
                WHERE dfc.input_id = input.id
                    AND dfc.type = 'from'
                    AND dfc.func_args::jsonb ? concat('"', %s, '"')
            )"""
            return pattern, method

        if not exact:
            needles = list(kht.needles)
            for needle in needles:
                if re.findall(r"[0-9]+", needle):
                    pattern, method = get_number_pattern_methods(needle)
                    pattern_methods.append((pattern, method))
                    pattern = f"{re.sub(r'([0-9]+|%d)', '%', re.escape(needle))}$"
                    method = "~ %s"
                else:
                    pattern = f"%{needle}"
                    method = "LIKE %s"
                pattern_methods.append((pattern, method))
        else:
            if re.findall(r"[0-9]+", keyword):
                pattern, method = get_number_pattern_methods(keyword)
                pattern_methods.append((pattern, method))
            pattern_methods.append((keyword, "= %s"))

        for pattern, method in pattern_methods:
            cmd = (
                FETCH_NAMED_ENTRIES_CMD
                + """
            WHERE
            """
                + (
                    ("LOWER(keyword)" if not case_sensitive else "keyword")
                    + " "
                    + method
                )
            )
            final_pattern = pattern if case_sensitive else pattern.lower()
            cur.execute(cmd, (final_pattern,))
            # get result
            new_results = fetch_data(cur, many=True)
            # if we have too many results, we don't need to search more
            if (
                len(pattern) <= 5
                and len(new_results) > 1000
                and results
                and search_patterns
            ):
                continue
            results.extend(new_results)
            search_patterns.append(pattern)

        cur.close()

        print(f"Search patterns for {keyword}: {search_patterns}")

        uniq_results = self._get_uniq_results(results)

        filtered_input_id = {entry["input_id"] for entry in self.entries}
        uniq_results = [
            result for result in uniq_results if result["input_id"] in filtered_input_id
        ]

        return uniq_results


class VarCLRNamedConstantSearcher(ConstantSearcher):
    """Use VarCLR results to search similar input entries
    VarCLR does not fit our use case, so it is not used
    """

    @cached_property
    def model(self):
        from varclr.models.model import Encoder

        return Encoder.from_pretrained("varclr-codebert")

    def search(self, knowledge, *args, **kwargs) -> list:
        protocol = knowledge["target"]["protocol"]
        assert protocol == "kv"

        keyword = knowledge["target"]["keyword"]

        search_results = self.search_by_keyword(keyword, threshold=0.9)

        return search_results

    def search_by_keyword(self, keyword, threshold):
        print(keyword)
        if not keyword:
            return []

        def gen_groups():
            tmp_entries = []
            for entry in self.entries:
                tmp_entries.append(entry)
                if len(tmp_entries) >= 5000:
                    yield tmp_entries
                    tmp_entries = []
            if tmp_entries:
                yield tmp_entries

        results = []
        for tmp_entries in gen_groups():
            tmp_keywords = [entry["keyword"] for entry in tmp_entries]
            sims = self.model.cross_score([keyword], tmp_keywords)[0]
            for sim, tmp_entry in zip(sims, tmp_entries):
                if sim > threshold:
                    results.append(tmp_entry)

        return results


class LLMNamedConstantSearcher(ConstantSearcher):
    """Use LLM results to search similar input entries"""

    def __init__(
        self, conn, entries, func_models, name_sim_dictionary, *args, **kwargs
    ):
        super().__init__(conn, entries, func_models, *args, **kwargs)
        self.name_sim_dictionary = name_sim_dictionary
        self.heuristic_searcher = HeuristicNamedConstantSearcher(
            conn, entries, func_models
        )

    def search(self, knowledge, *args, **kwargs) -> list:
        print("Searching with LLMNamedConstantSearcher")
        exact = kwargs.get("exact", False)
        search_results = self.heuristic_searcher.search(knowledge, *args, **kwargs)
        if exact:
            return search_results

        protocol = knowledge["target"]["protocol"]
        assert protocol == "kv"

        keyword = knowledge["target"]["keyword"]
        search_results += self.search_by_keyword(keyword)
        uniq_results = self._get_uniq_results(search_results)

        return uniq_results

    def search_by_keyword(self, keyword):
        search_results = []
        keywords = self.name_sim_dictionary.get(keyword.lower(), set())
        if not keywords:
            return search_results

        for entry in self.entries:
            if not entry["keyword"]:
                continue

            if entry["keyword"].lower() in keywords:
                search_results.append(entry)

        return search_results


def fetch_data(cur, many=True):
    """
    Fetch data from cursor
    """
    if many:
        rows = list(cur.fetchall())
    else:
        rows = [cur.fetchone()]

    results = []
    for row in rows:
        result = dict(zip([col.name for col in cur.description], row))
        results.append(result)
    return results


def parse():
    """Parse arguments"""
    parser = argparse.ArgumentParser()
    parser.add_argument("config_path", type=str, help="path to config file")
    parser.add_argument("db_name", type=str, help="database name")
    parser.add_argument("func_model_path", type=str, help="path to function model")
    parser.add_argument(
        "sim_dictionary", type=str, help="path to name similarity dictionary"
    )
    parser.add_argument(
        "named_input_entries", type=str, help="path to named input entries"
    )
    parser.add_argument(
        "unnamed_input_entries", type=str, help="path to unnamed input entries"
    )
    parser.add_argument("output_path", type=str, help="path to output file")

    parser.add_argument("--exact", action="store_true", help="exact search")
    parser.add_argument(
        "--detect",
        type=str,
        help="path to signature, used for searching entries for vulnerability detection",
    )
    parser.add_argument(
        "--sig-gen",
        type=str,
        help="path to vuln_info, used for searching entries for signature genration",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="force to search new results and overwrite existing ones",
    )
    args = parser.parse_args()

    if not args.sig_gen and not args.detect:
        print("Error: please specify --sig-gen or --detect", file=sys.stderr)
        sys.exit(1)
    elif args.sig_gen and args.detect:
        print(
            "Error: please specify only one of --sig-gen or --detect", file=sys.stderr
        )
        sys.exit(1)

    return args


def extract_visible_strings(data):
    """
    Extracts strings of visible ASCII characters whose length is greater than 4.
    """
    # Use a regular expression to find sequences of ASCII characters from space (32) to tilde (~) (127)
    pattern = re.compile(b"[\x20-\x7E]{5,}")
    return [match.group().decode("ascii") for match in pattern.finditer(data)]


def extract_magic_numbers(data):
    """
    Extracts uncommon 4-byte integers that might be used as magic numbers.
    """

    def is_uncommon_magic_number(num):
        common_values = {
            0xCAFEBABE,
            0xDEADBEEF,
        }  # Example common values; modify as required
        if num in common_values or num == 0:
            return False
        if (num & (num - 1)) == 0:  # Check if num is a power of 2
            return False
        return True

    magic_numbers = []
    for i in range(len(data) - 4 + 1):
        # ignore if there are more than 3 visible characters in the 4-byte sequence
        visible_count = 0
        for byte_offset in range(4):
            if data[i + byte_offset] > 0x20 or data[i + byte_offset] <= 0x7E:
                visible_count += 1
        if len(visible_count) > 3:
            continue

        (num,) = struct.unpack_from("I", data, i)
        if is_uncommon_magic_number(num):
            magic_numbers.append(num)
    return magic_numbers


def handle_sig_gen_search_results(vuln_info, results):

    # Filter results by target firmware
    new_results = []
    for result in results:
        target_firmware_id = os.path.basename(vuln_info["firmware_filename"])
        if result["firmware_id"] != target_firmware_id:
            continue
        new_results.append(result)
        result["extra_info"]["poc_info"]["key_keywords"] = result["extra_info"][
            "poc_info"
        ]["keywords"]
    results = new_results

    # Group results by location
    new_results = []

    def get_group_key(r):
        return (r["path"], r["entry_addr"])

    results.sort(key=get_group_key)
    for _, group in groupby(results, get_group_key):
        group = list(group)
        if len(group) < 2:
            new_results.extend(group)
            continue

        # Merge the results into the entry with the smallest base address
        merged_result = dict(group[0])
        source_info = []
        visited_source_addr = set()
        for entry in group:
            for source_info_raw in entry["source_info"]:
                if source_info_raw["addr"] not in visited_source_addr:
                    visited_source_addr.add(source_info_raw["addr"])
                    source_info.append(source_info_raw)

        merged_result["source_info"] = source_info

        new_results.append(merged_result)

    return new_results


def main():
    """Search Main"""
    global UNPACK_DIR
    args = parse()
    config_path = args.config_path
    db_name = args.db_name
    func_model_path = args.func_model_path
    output_path = args.output_path

    exact_mode = args.exact or args.sig_gen

    config = yaml.safe_load(open(config_path, "r", encoding="utf-8"))
    UNPACK_DIR = os.path.join(config["firmware_dir"], "unpacked")

    conn = psycopg2.connect(
        database=db_name,
        user=config["db_user"],
        password=config["db_user_passwd"],
        host="localhost",
        port=5432,
    )

    # load func_models
    with open(func_model_path, "r", encoding="utf-8") as func_model_fp:
        func_models = json.load(func_model_fp)

    named_input_entries_path = args.named_input_entries
    unnamed_input_entries_path = args.unnamed_input_entries
    name_sim_dictionary_path = args.sim_dictionary if args.detect else None

    search_manager = InputSearchManager(
        conn,
        func_models,
        named_input_entries_path,
        unnamed_input_entries_path,
        name_sim_dictionary_path,
    )

    if args.detect:
        ana_result_path = args.detect
        # Vulnerability detection-oriented searching
        # load analysis result
        if not os.path.exists(ana_result_path):
            print(f"Error: {ana_result_path} does not exist", file=sys.stderr)
            return
        with open(ana_result_path, "r", encoding="utf-8") as ana_res_fp:
            ana_result = json.load(ana_res_fp)

        if not ana_result:
            print(f"Error: {ana_result_path} is empty", file=sys.stderr)
            return

        knowledge = dict(ana_result)
        knowledge["poc_info"] = knowledge["target_info"]["extra_info"]["poc_info"]

        key_vars = ana_result["entry_info"].get("key_vars", [])
        key_consts = ana_result["entry_info"]["key_consts"] if not key_vars else []

        print(f"Search {os.path.basename(ana_result_path)}")
    else:
        assert args.sig_gen
        assert os.path.exists(args.sig_gen)
        vuln_info = json.load(open(args.sig_gen, "r", encoding="utf-8"))

        key_vars = vuln_info["input"].get("kv", {}).keys()

        raw = vuln_info["input"].get("raw", "")
        stream = b""
        for raw_bytes in raw:
            stream += base64.b64decode(raw_bytes)
        key_consts = extract_visible_strings(stream)
        key_consts += extract_magic_numbers(stream)

        vuln_dir = os.path.dirname(args.sig_gen)
        vuln_name = os.path.basename(vuln_dir).split(".")[0]
        vuln_vendor = os.path.dirname(vuln_dir).split("/")[-1]

        vuln_input = vuln_info["input"]

        knowledge = {
            "vuln_name": vuln_name,
            "vuln_vendor": vuln_vendor,
            "vuln_info": vuln_info,
            "poc_info": {
                "keywords": list(key_vars),
                "input": vuln_input,
            },
        }

        print(f"Search {os.path.basename(args.sig_gen)}")

    print(f"  - Named constants: {key_vars}")
    print(f"  - Unnamed constants: {key_consts}")

    results = []
    for keyword in key_vars:
        knowledge["target"] = {"protocol": "kv", "keyword": keyword}
        # search
        round_results = search_manager.search(knowledge, exact=exact_mode)
        results.extend(round_results)

    for constant in key_consts:
        knowledge["target"] = {"protocol": "raw", "constant": constant}
        # search
        round_results = search_manager.search(knowledge, exact=exact_mode)
        results.extend(round_results)

    print(f"Generated {len(results)} results")

    # For signature generation, we group the discovered entries
    # to reduce time overhead.
    if args.sig_gen:
        results = handle_sig_gen_search_results(vuln_info, results)

        print(f"Get {len(results)} results for signature generation")

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    if not args.force:
        print(f"Load and merge existing results from {output_path}")
        results = _load_and_merge_existing_results(output_path, results)

    with open(output_path, "w+", encoding="utf-8") as output_fp:
        json.dump(results, output_fp, indent=2)


def _load_and_merge_existing_results(output_path, results):
    add_count = 0
    if not os.path.exists(output_path) or not os.path.getsize(output_path):
        return results
    with open(output_path, "r", encoding="utf-8") as output_fp:
        existing_results = json.load(output_fp)
    existing_identifiers = {
        TargetInfo.refer_id(TargetInfo.load_from_search_result(result))
        for result in existing_results
    }
    for result in results:
        result_identifier = TargetInfo.refer_id(
            TargetInfo.load_from_search_result(result)
        )
        if result_identifier in existing_identifiers:
            continue
        existing_results.append(result)
        add_count += 1
    print(f"Added {add_count} new results")
    print(f"Total {len(existing_results)} results")
    results = existing_results
    return results


if __name__ == "__main__":
    main()
